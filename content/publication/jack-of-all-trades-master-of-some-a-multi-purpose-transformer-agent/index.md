---
title: "Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent"
publication_types:
  - "3"
authors:
  - Quentin Gallouédec
  - Edward Beeching
  - Clément Romac
  - Emmanuel Dellandréa
publication: "arXiv preprint arXiv:2402.09844"
abstract: "The search for a general model that can operate seamlessly across multiple domains remains a key goal in machine learning research. The prevailing methodology in Reinforcement Learning (RL) typically limits models to a single task within a unimodal framework, a limitation that contrasts with the broader vision of a versatile, multi-domain model. In this paper, we present Jack of All Trades (JAT), a transformer-based model with a unique design optimized for handling sequential decision-making tasks and multimodal data types. The JAT model demonstrates its robust capabilities and versatility by achieving strong performance on very different RL benchmarks, along with promising results on Computer Vision (CV) and Natural Language Processing (NLP) tasks, all using a single set of weights. The JAT model marks a significant step towards more general, cross-domain AI model design, and notably, it is the first model of its kind to be fully open-sourced, including a pioneering generalpurpose dataset."
draft: false
featured: false
image:
  filename: featured
  focal_point: Smart
  preview_only: false
date: 2024-02-15T00:00:00.000Z
links:
- name: Paper
  url: 'https://arxiv.org/abs/2402.09844'
- name: Code
  url: 'https://github.com/huggingface/jat'
- name: Model
  url: 'https://huggingface.co/jat-project/jat'
---
